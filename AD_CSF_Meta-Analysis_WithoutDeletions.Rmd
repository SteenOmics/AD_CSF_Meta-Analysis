---
title: "AD_CSF_Meta-Analysis"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    code_folding: hide
date: '2022-04-20'
---
# 0. Preparations & Imports

### Libraries, functions, imports

Import Libraries
```{r, libraries, message=FALSE, class.source = 'fold-hide'}
library(readxl)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(msigdbr)
library(clusterProfiler)
library(ggrepel)
library(ggthemes)
library(gridExtra)
library(eulerr)
library(pROC)
library(ggbeeswarm)
library(ComplexHeatmap)
library(circlize)
library(extrafont)
library(wesanderson)
library(DT)
library(enrichR)
library(table1)
loadfonts(device = "win")
```
### Functions
Create functions to import Fragpipe TMT and LFQ data.
Create a function to detect and remove outliers (and visualize).
```{r, class.source = 'fold-hide'}
#Create Functions to clean the datasets. four in total: TMT-protein, TMT-peptide, LFQ-protein, LFQ-peptide.
#Goal is to get to a long(tidy)format for each. For LFQ ones we also log transform.
cleanTMT_protein <- function(dataset){
  colnames_TMT_Protein <- colnames(dataset)[6:ncol(dataset)]
  dataset <- dataset %>% gather(colnames_TMT_Protein, key = "Sample", value = "Intensity") %>%
  mutate(ID = paste0(Index, "_", Gene)) %>%
  dplyr::select(ID, Sample, Intensity)
  return(dataset)
}
cleanLFQ_protein <- function(dataset){
  names(dataset)[names(dataset) == 'Protein ID'] <- 'ProteinID'
  dataset <- dataset %>%
    mutate(ID = paste0(ProteinID, "_", Gene)) %>%
    dplyr::select(ID, contains("MaxLFQ Total Intensity")) #%>% select(-contains("MaxLFQ"))
  dataset <- dataset %>%
    gather(colnames(dataset)[2:ncol(dataset)], key = "Sample", value = "Intensity") 
}

OutlierRemover <- function(dataset, name){
  #Determine correlations between sample and theoretical
  SampleCorrelations <- dataset%>%
    mutate(SampleDX = paste0(Sample,"_", DX)) %>%
    group_by(ID) %>%
    mutate(medianProtein = median(Intensity, na.rm = T)) %>%
    ungroup() %>%
    group_by(Sample) %>%
    mutate(SampleCor = cor(Intensity, medianProtein, method = "pearson", use="complete.obs")) %>%
    ungroup() %>%
    distinct(SampleDX, .keep_all = T)
  
  SampleCorrelations <- SampleCorrelations %>%
    mutate(Outlier = SampleCor < (1 - 4*sd(unique(SampleCorrelations$SampleCor))))
  
    #Make the DF that we will return (i.e. without outliers)
  returnDataset <- dataset %>%
    dplyr::filter(Sample %in% dplyr::filter(SampleCorrelations, Outlier == F)$Sample) %>%
    dplyr::select(ID, Sample, DX, Intensity)  
  
  #Purely for visualization: Also attached PCA Plots of the removed samples
  
  #PCA PLOT: 70% cut off
  ProteinsToKeep <- dataset %>%
    group_by(ID) %>%
    summarise(PercentMissing = sum(!is.na(Intensity))/ length(unique(dataset$Sample))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)
    
  #Half minimum value (per protein) imputation
  PCA_DF <- dataset %>% 
    dplyr::filter(ID %in% ProteinsToKeep$ID) %>%
    group_by(ID) %>%
    mutate(IntensImputed = replace_na(Intensity, mean(Intensity, na.rm = T)/2)) %>%
    mutate(SampleDX = paste0(Sample,"_", DX)) %>%
    dplyr::select(ID, SampleDX, IntensImputed) %>%
    spread(key = "ID", value = "IntensImputed") %>%
    column_to_rownames("SampleDX")

  #scale and PCA
  PCA_DF_Results <- prcomp(scale(as.matrix(PCA_DF)))
  eigs <- PCA_DF_Results$sdev^2
  variance_percentage <- (eigs / sum(eigs))*100
  pc1var <- round(variance_percentage[1],digits=0)
  pc2var <- round(variance_percentage[2],digits=0)
  
  #Plot
  plot(left_join(SampleCorrelations, rownames_to_column(data.frame(PCA_DF_Results$x)), by = c("SampleDX" = "rowname")) %>%
    ggplot(aes(x = PC1, y = PC2, colour = Outlier)) +
    geom_point() +
    theme_bw() +
    xlab(paste('PC1',' (',pc1var,'% variance)',sep='')) +
    ylab(paste('PC2',' (',pc2var,'% variance)',sep='')) +
    ggtitle(name))
  
  #Print and Return
  print(paste("The following were removed from:", name, toString(dplyr::filter(SampleCorrelations, Outlier == T)$SampleDX)))
  return(returnDataset)
}
```

Function for Ttest (using 70% cut off) & visualization
```{r}
Ttest_AD <- function(dataset){
  #70% cut off
  ProteinsToKeep <- dataset %>%
    group_by(ID) %>%
    summarise(PercentMissing = sum(!is.na(Intensity))/ length(unique(dataset$Sample))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)

  dataset_ttest <- dataset %>%
    filter(ID %in% ProteinsToKeep$ID) %>%
    drop_na(Intensity) %>%
    drop_na(DX) %>%
    group_by(ID) %>%
    wilcox_test(Intensity ~ DX, detailed = T) %>%
    adjust_pvalue(method = "BH") %>%
    mutate(SIGNIFICANT = p.adj < 0.05) %>%
  mutate(log10_padj = -1*log10(p.adj))
  
  ttestPlot <- dataset_ttest %>%
    dplyr::mutate(FC = estimate) %>%
    mutate(log10adjustP = -1*log10(p.adj)) %>%
    mutate(Direction = ifelse(p.adj > 0.05, "NotSignificant", ifelse(FC < 0, "Down", "Up"))) %>%
    ggplot(aes(x = FC, y = log10adjustP, fill = Direction)) +
    geom_point(size = 3, shape = 21) +
    scale_fill_manual(values = c("Down" = "#164db5","NotSignificant" = "darkgrey", "Up" = "#d90429")) +
    theme_pubr() +
    geom_hline(yintercept = 1.3, linetype = 2, alpha = 0.7) +
    xlab("Fold Change (Old - Young)") +
    ylab("-log10(adjusted p-value)") +
    theme(legend.position= "none")

  plot(ttestPlot)
  
  return(dataset_ttest)
}
```

### Imports
Import datasets
```{r, import and clean DF, message=FALSE, class.source = 'fold-hide'}
Dayon_protein_clean <- cleanTMT_protein(read_tsv("Datasets/Dayon_abundance_protein_None.tsv"))
Omar_protein_clean <- cleanTMT_protein(read_tsv("Datasets/Omar_abundance_protein_None.tsv"))
Sathe_protein_clean <- cleanTMT_protein(read_tsv("Datasets/Sathe_abundance_protein_None.tsv"))
Zetterberg_protein_clean <- cleanLFQ_protein(read_tsv("Datasets/Zetterberg_combined_protein.tsv"))
Lleo_protein_clean <- cleanLFQ_protein(read_tsv("Datasets/Lleo_combined_protein.tsv"))
Wang_protein_clean <- cleanLFQ_protein(read_tsv("Datasets/Wang_combined_protein.tsv"))
Multhaup_protein_clean <- cleanLFQ_protein(read_tsv("Datasets/Multhaup_combined_protein.tsv"))
Khoonsari_protein_clean <- cleanLFQ_protein(read_tsv("Datasets/Khoonsari_combined_protein.tsv"))
```

# 1. Meta-Analysis

## Clean and combine with Clinical {.tabset}

Each dataset required a slighly different approach to prepare it for the combinatory meta-analysis. Per dataset we first normalize (with or without pool etc) followed by the removal of outliers. Lastly, we set the clinical data based on sample name or meta information with a given publication.



### Dayon

#### Normalization
We normalize on reference samples. Fragpipe TMTintegrator had issues with two reference samples hence I named them SP and bool
```{r, normalize dayon, class.source = 'fold-hide'}
#First calculate per sample the median intensity.
#Then take the mean of all those medians.
Dayon_protein_clean_references <- 
  Dayon_protein_clean %>%
  mutate(Intensity = 2^Intensity)%>%
  dplyr::filter(grepl('Bool|SP', Sample)) %>%
  group_by(Sample) %>%
  summarise(PerSampleMedian = median(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(AverageMedian = mean(PerSampleMedian))
Dayon_averagemedianofreferences <- mean(Dayon_protein_clean_references$AverageMedian)

#Only select samples, calculate median per sample.
#Determine per sample normalization factor
#apply it to intensity column. 
#clean up.
Dayon_protein_clean_noreferences <- 
  Dayon_protein_clean %>%
  mutate(Intensity = 2^Intensity)%>%
  dplyr::filter(!grepl('Bool|SP', Sample)) %>%
  group_by(Sample) %>%
  mutate(PerSampleMedian = median(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Dayon_averagemedianofreferences/ PerSampleMedian) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  mutate(Intensity = log2(Intensity)) %>%
  dplyr::select(ID, Sample, Intensity)
```

#### mean calculation
This dataset had duplicates. We take average of each.
Looks like I did not properly capitalize each sample. We also account for that.
```{r, mean calculation dayon,class.source = 'fold-hide'}
#split sample name
#group sample_a and ID
#Replace intensity by mean of the two.
#only take one of the two.
#remove NaN's, clean up columns
Dayon_protein_clean_averaged <- 
Dayon_protein_clean_noreferences %>%
  mutate(sample_b = substr(Sample, 5,6)) %>% #260160 rows 
  mutate(Sample = str_to_title(substr(Sample, 1,4))) %>%
  group_by(Sample, ID) %>%
  mutate(Intensity = mean(Intensity, na.rm = TRUE)) %>%
  dplyr::filter(sample_b == "01") %>%
  na_if("NaN") %>%
  dplyr::select(ID, Sample, Intensity)
```

#### Set Clinical
This dataset did have some clinical data, but not which one is and isnt AD.
There is Tau/AB info. We use that. To be sure; we decided to only take the lowest (control) and highest quartile(AD).
```{r, clinical dayon,warning=FALSE,  class.source = 'fold-hide'}
#Dayon clinical Data
DayonClinical <- read_excel("Datasets/DayonClinical.xlsx", 
    col_types = c("text", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))

#calculate ratio, sort, split in four, select upper and lower
DayonClincalQuantiles <- DayonClinical %>%
  mutate(ratioABTAU = CSF_PTAU/CSF_AB42) %>%
  arrange(ratioABTAU) %>%
  mutate(quantile = ntile(ratioABTAU, 4)) %>%
  dplyr::filter(quantile %in% c(1,4)) %>%
  mutate(DX = ifelse(quantile == 1, "C", "AD"))

Dayonproteinclinical <- left_join(DayonClincalQuantiles, Dayon_protein_clean_averaged, by = c("Subject ID" = "Sample"), keep = TRUE) %>%
  dplyr::select(ID, Sample, DX, Intensity)


```

#### Outlier Selection
```{r, outlier Dayon, class.source = 'fold-hide'}
Dayonproteinclinical_NO <- OutlierRemover(Dayonproteinclinical, "Dayon")
```

#### Mann-Whitney U Test
```{r, ttest Dayon, class.source = 'fold-hide'}
Dayon_ttest <- Ttest_AD(Dayonproteinclinical) %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)

# put CSV, XLS, and PDF in a collection
DT::datatable(Dayon_ttest, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

Ttest_AD

### In-House

#### Normalization
We normalize on reference samples. These have the substring Ref (or Rof.. Again, small writing mistake)
We do work on un-log transformed data here.
```{r, normalize Omar, class.source = 'fold-hide'}
#First calculate per sample the median intensity.
#Then take the mean of all those medians.
Omar_protein_clean_references <- 
  Omar_protein_clean %>%
  mutate(Intensity = 2^Intensity) %>%
  dplyr::filter(grepl('Ref|Rof', Sample)) %>%
  group_by(Sample) %>%
  summarise(PerSampleMedian = median(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(AverageMedian = mean(PerSampleMedian))
Omar_averagemedianofreferences <- mean(Omar_protein_clean_references$AverageMedian)

#Only select samples, calculate median per sample.
#Determine per sample normalization factor
#apply it to intensity column. 
#clean up.
Omar_protein_clean_noreferences <- 
  Omar_protein_clean %>%
  mutate(Intensity = 2^Intensity)%>%
  dplyr::filter(!grepl('Bool|SP', Sample)) %>%
  group_by(Sample) %>%
  mutate(PerSampleMedian = median(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Omar_averagemedianofreferences/ PerSampleMedian) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  mutate(Intensity = log2(Intensity)) %>%
  dplyr::select(ID, Sample, Intensity)
```

#### mean calculation
This dataset had duplicates. We take average of each.
Made a small mistake by not applying underscore everywhere. Remove it to solve the issue.
```{r, mean calculation omar, class.source = 'fold-hide'}
#split sample name
#group sample_a and ID
#Replace intensity by mean of the two.
#only take one of the two.
#remove NaN's, clean up columns
Omar_protein_clean_averaged <- 
Omar_protein_clean_noreferences %>%
  mutate(Sample = str_remove_all(Sample, "_")) %>%
  mutate(sample_b = substr(Sample, 3, 3)) %>% #260160 rows 
  mutate(Sample = str_to_title(substr(Sample, 1,2))) %>%
  group_by(Sample, ID) %>%
  mutate(Intensity = mean(Intensity, na.rm = TRUE)) %>%
  dplyr::filter(sample_b == "1") %>%
  na_if("NaN") %>%
  dplyr::select(ID, Sample, Intensity)
```

#### Clinical
This dataset had AD, control and PSP. Only take AD and Control.
```{r, add clinical info omar, class.source = 'fold-hide'}
Omarproteinclinical <- Omar_protein_clean_averaged %>%
  dplyr::filter(grepl('A|C', Sample)) %>% 
  mutate(sample_b = substr(Sample, 1, 1)) %>%
  mutate(DX = ifelse(sample_b == "A", "AD", "C")) %>%
  dplyr::select(ID, Sample, DX, Intensity)

```

#### Outlier Selection
```{r, outlier selection omar, class.source = 'fold-hide'}
Omarproteinclinical_NO <- OutlierRemover(Omarproteinclinical, "Omar")
```

#### Mann-Whitney U Test
```{r, ttest Omar, class.source = 'fold-hide'}
omar_ttest <- Ttest_AD(Omarproteinclinical_NO) %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)

# put CSV, XLS, and PDF in a collection
DT::datatable(omar_ttest, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

### Sathe

#### Normalization
We determine the summed intensity (un-transformed) of each sample.
We take the median value of all those summed intensities and use that for normalization.
```{r, normalization sathe , class.source = 'fold-hide'}
Sathe_medianSummedIntensity <- mean((
  Sathe_protein_clean %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  group_by(Sample) %>%
  summarise(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(medianOfSummedIntensities = median(PerSampleSum)))$medianOfSummedIntensities)

Sathe_protein_normalized <-   
Sathe_protein_clean %>%
  group_by(Sample) %>%
  mutate(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Sathe_medianSummedIntensity/ PerSampleSum) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  dplyr::select(ID, Sample, Intensity) %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  mutate(Intensity = log2(Intensity))
```


#### Mean Calculation
This dataset had duplicates. We take average of each.
```{r, mean sathe, class.source = 'fold-hide'}
#clean and split sample name
#Replace intensity by mean of the two.
#only take one of the two.
#remove NaN's, clean up columns
Sathe_protein_clean_averaged <- 
  Sathe_protein_clean %>%
  separate(Sample, c("Sample", "second")) %>%
  group_by(Sample, ID) %>%
  mutate(Intensity = mean(Intensity, na.rm = TRUE)) %>%
  dplyr::filter(second == "1") %>%
  na_if("NaN") %>%
  dplyr::select(ID, Sample, Intensity)
```

#### Clinical
clinical variables were described in manuscript. We extract it from TMT label.
```{r clinical sathe, , class.source = 'fold-hide'}
Satheproteinclinical <- 
  Sathe_protein_clean_averaged %>%
  mutate(AD= grepl("C",Sample)) %>%
  mutate(DX = ifelse(AD == TRUE, "C", "AD")) %>%
  dplyr::select(ID, Sample, DX, Intensity)
```


#### Outlier Selection
```{r, outlier selection sathe, class.source = 'fold-hide'}
Satheproteinclinical_NO <- OutlierRemover(Satheproteinclinical, "Sathe")
```


#### Mann-Whitney U Test
```{r, ttest sathe, class.source = 'fold-hide'}
sathe_ttest <- Ttest_AD(Satheproteinclinical_NO) %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)

# put CSV, XLS, and PDF in a collection
DT::datatable(sathe_ttest, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

### Lleo

#### Normalization
We determine the summed intensity (un-transformed) of each sample.
We take the median value of all those summed intensities and use that for normalization
```{r, normalization lleo , class.source = 'fold-hide'}
Lleo_medianSummedIntensity <- mean(
  (Lleo_protein_clean %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  group_by(Sample) %>%
  summarise(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(medianOfSummedIntensities = median(PerSampleSum)))$medianOfSummedIntensities
  )

Lleo_protein_normalized <-   
Lleo_protein_clean %>%
  group_by(Sample) %>%
  mutate(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Lleo_medianSummedIntensity/ PerSampleSum) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  dplyr::select(ID, Sample, Intensity) %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  mutate(Intensity = log2(Intensity))
```

#### Clinical
This dataset only has four samples. One is AD and 3 control.
01_01 --> AD1
02_02 --> C1
01_02 --> C4
02_01 --> C5
Each sample is the POOL of 10 samples.
```{r, clinical  lleo , class.source = 'fold-hide'}
Lleoproteinclinical <- Lleo_protein_normalized %>%
  mutate(Sample = str_remove_all(Sample, " MaxLFQ Total Intensity")) %>%
  mutate(DX = ifelse(Sample == "01_01", "AD", "C")) %>%
  dplyr::select(ID, Sample, DX, Intensity)
```

#### Outlier Selection
```{r, outlier selection lleo, class.source = 'fold-hide'}
Lleoproteinclinical_NO <- OutlierRemover(Lleoproteinclinical, "Lleo")
```

#### Mann-Whitney U Test
Not available in Lleo data due to single AD sample.

### Khoonsari

#### Normalization
We determine the summed intensity (un-transformed) of each sample.
We take the median value of all those summed intensities and use that for normalization
```{r, normalization khoonsari , class.source = 'fold-hide'}
Khoonsari_medianSummedIntensity <- mean(
  (Khoonsari_protein_clean %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  group_by(Sample) %>%
  summarise(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(medianOfSummedIntensities = median(PerSampleSum)))$medianOfSummedIntensities
  )

Khoonsari_protein_normalized <-   
Khoonsari_protein_clean %>%
  group_by(Sample) %>%
  mutate(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Khoonsari_medianSummedIntensity/ PerSampleSum) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  dplyr::select(ID, Sample, Intensity) %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  mutate(Intensity = log2(Intensity))
```

#### Mean Calculation

This dataset had duplicates. We take average of each.
```{r, mean khoonsari, warning=FALSE , class.source = 'fold-hide'}
#clean and split sample name
#Replace intensity by mean of the two.
#only take one of the two.
#remove NaN's, clean up columns
Khoonsari_protein_clean_averaged <- 
  Khoonsari_protein_normalized %>%
  mutate(Sample = str_remove_all(Sample, " Total Intensity")) %>%
  separate(Sample, c("Sample", "second")) %>%
  group_by(Sample, ID) %>%
  mutate(Intensity = mean(Intensity, na.rm = TRUE)) %>%
  dplyr::filter(second == "1") %>%
  na_if("NaN") %>%
  dplyr::select(ID, Sample, Intensity)
```

#### Clinical
clinical data in rawfile name.
```{r, clinical khoonsari , class.source = 'fold-hide'}
Khoonsariproteinclinical <-
Khoonsari_protein_clean_averaged %>%
  mutate(AD= grepl("AD",Sample)) %>%
  mutate(DX = ifelse(AD == TRUE, "AD", "C")) %>%
  dplyr::select(ID, Sample, DX, Intensity)
```


#### Outlier Selection
```{r, outlier selection khoonsari, class.source = 'fold-hide'}
Khoonsariproteinclinical_NO <- OutlierRemover(Khoonsariproteinclinical, "Khoonsari")
```

#### Mann-Whitney U Test
```{r, ttest khoonsari, class.source = 'fold-hide'}
khoonsari_ttest <- Ttest_AD(Khoonsariproteinclinical_NO) %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)

# put CSV, XLS, and PDF in a collection
DT::datatable(khoonsari_ttest, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

### Barucker

#### Normalization
We determine the summed intensity (un-transformed) of each sample.
We take the median value of all those summed intensities and use that for normalization
```{r, normalize multhaup , class.source = 'fold-hide'}
Multhaup_medianSummedIntensity <- mean(
  (Multhaup_protein_clean %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  group_by(Sample) %>%
  summarise(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(medianOfSummedIntensities = median(PerSampleSum)))$medianOfSummedIntensities
  )

Multhaup_protein_normalized <-   
Multhaup_protein_clean %>%
  group_by(Sample) %>%
  mutate(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Multhaup_medianSummedIntensity/ PerSampleSum) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  dplyr::select(ID, Sample, Intensity) %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  mutate(Intensity = log2(Intensity))
```

#### Clinical
Clinical info is in the raw file name.
```{r, clinical multhaup , class.source = 'fold-hide'}
Multhaupproteinclinical <-
Multhaup_protein_normalized %>%
  mutate(Sample = str_remove_all(Sample, " MaxLFQ Total Intensity")) %>%
  mutate(NAD= grepl("NAD",Sample)) %>%
  mutate(DX = ifelse(NAD == TRUE, "C", "AD")) %>%
  dplyr::select(ID, Sample, DX, Intensity)
```


#### Outlier Selection
```{r, outlier selection Multhaup, class.source = 'fold-hide'}
Multhaupproteinclinical_NO <- OutlierRemover(Multhaupproteinclinical, "Barucker")
```


#### Mann-Whitney U Test
```{r, ttest multhaup, class.source = 'fold-hide'}
multhaup_ttest <- Ttest_AD(Multhaupproteinclinical_NO) %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)

# put CSV, XLS, and PDF in a collection
DT::datatable(multhaup_ttest, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

### Wang


#### Normalization
We determine the summed intensity (un-transformed) of each sample.
We take the median value of all those summed intensities and use that for normalization
```{r, normalize wang , class.source = 'fold-hide'}
Wang_medianSummedIntensity <- mean(
  (Wang_protein_clean %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  group_by(Sample) %>%
  summarise(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(medianOfSummedIntensities = median(PerSampleSum)))$medianOfSummedIntensities
  )

Wang_protein_normalized <-   
Wang_protein_clean %>%
  group_by(Sample) %>%
  mutate(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Wang_medianSummedIntensity/ PerSampleSum) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  dplyr::select(ID, Sample, Intensity) %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  mutate(Intensity = log2(Intensity))
```

#### Mean Calculation

This dataset had Triplicates We take average of each.
```{r, mean wang , warning=FALSE, class.source = 'fold-hide'}
#clean and split sample name
#Replace intensity by mean of the two.
#only take one of the two.
#remove NaN's, clean up columns
Wang_protein_clean_averaged <- 
  Wang_protein_normalized %>%
  mutate(Sample = str_remove_all(Sample, " Total Intensity")) %>%
  separate(Sample, c("Sample", "second", "third", "fourth")) %>%
  mutate(Sample = paste(Sample, second,third, sep = "_")) %>%
  group_by(Sample, ID) %>%
  mutate(Intensity = mean(Intensity, na.rm = TRUE)) %>%
  dplyr::filter(fourth == "1") %>%
  na_if("NaN") %>%
  dplyr::select(ID, Sample, Intensity)
```

#### Clinical
Clinical data given by group over email by Wang group.
```{r, clinical wang , class.source = 'fold-hide'}
Wang_Clinical <- read_excel("Datasets/Wang_Clinical.xlsx")
Wang_Clinical$Sample <- as.character(Wang_Clinical$Sample)

#Split again for matching with excel table
Wang_protein_clean_averaged <- Wang_protein_clean_averaged %>%
   separate(Sample, c("first", "second", "third"), remove = F) 

Wangproteinclinical <-
left_join(Wang_Clinical, Wang_protein_clean_averaged, by = c("Sample" = "third")) %>%
  mutate(Sample = Sample.y) %>%
  dplyr::filter(!DX == "MCI") %>%
  dplyr::select(ID, Sample, DX, Intensity)
```


#### Outlier Selection
```{r, outlier selection Wang, class.source = 'fold-hide'}
Wangproteinclinical_NO <- OutlierRemover(Wangproteinclinical, "Wang")
```

#### Mann-Whitney U Test
```{r, ttest wang, class.source = 'fold-hide'}
wang_ttest <- Ttest_AD(Wangproteinclinical_NO) %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)

# put CSV, XLS, and PDF in a collection
DT::datatable(wang_ttest, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```


## Combining data & Z-scoring of Data
Add an identifier to each dataset, Z-score the data, combine the data (once for un-transformed, once for z-scored).
```{r, combine all data, class.source = 'fold-hide'}
Dayonproteinclinical_NO$Dataset <- "Dayon"
Omarproteinclinical_NO$Dataset <- "In-house"
Satheproteinclinical_NO$Dataset <- "Sathe"
Lleoproteinclinical_NO$Dataset <- "Lleó"
Khoonsariproteinclinical_NO$Dataset <- "Khoonsari"
Multhaupproteinclinical_NO$Dataset <- "Barucker"
Wangproteinclinical_NO$Dataset <- "Wang"

Allproteinclinical <- rbind(Dayonproteinclinical_NO,
                            Omarproteinclinical_NO,
                            Satheproteinclinical_NO,
                            Lleoproteinclinical_NO,
                            Khoonsariproteinclinical_NO,
                            Multhaupproteinclinical_NO,
                            Wangproteinclinical_NO)

#Function to Z-score Data
Z_Scorer <- function(dataset){

  MeanSD_DF <- dataset %>%
    group_by(ID) %>%
    filter(DX == "C") %>%
    summarise(mean = mean(Intensity, na.rm = T),
              sd = sd(Intensity, na.rm=T))
  
  Zscored <- left_join(dataset, MeanSD_DF, by = c("ID" = "ID")) %>%
    mutate(Z_score = (Intensity - mean)/sd) %>%
    dplyr::select(ID, Sample, DX, Z_score, Dataset)
  
  return(Zscored)
}

Dayonproteinclinical_Zscore <- Z_Scorer(Dayonproteinclinical_NO)
Omarproteinclinical_Zscore <- Z_Scorer(Omarproteinclinical_NO)
Satheproteinclinical_Zscore <- Z_Scorer(Satheproteinclinical_NO)
Lleoproteinclinical_Zscore <- Z_Scorer(Lleoproteinclinical_NO)
Khoonsariproteinclinical_Zscore <- Z_Scorer(Khoonsariproteinclinical_NO)
Multhaupproteinclinical_Zscore <- Z_Scorer(Multhaupproteinclinical_NO)
Wangproteinclinical_Zscore <- Z_Scorer(Wangproteinclinical_NO)

Allproteinclinical_Zscored <- rbind(Dayonproteinclinical_Zscore,
                            Omarproteinclinical_Zscore,
                            Satheproteinclinical_Zscore,
                            Lleoproteinclinical_Zscore,
                            Khoonsariproteinclinical_Zscore,
                            Multhaupproteinclinical_Zscore,
                            Wangproteinclinical_Zscore)
```

## PCA Plots before After Z-scoring
To see the effect of Z-scoring we make a PCA plot before and after.
```{r, pcaplots, class.source = 'fold-hide', fig.width=8, fig.height=4}
PCA_PLOT <- function(dataset, dataset2) {
  
  #PCA PLOT: 70% cut off
  ProteinsToKeep <- dataset %>%
    group_by(ID) %>%
    summarise(PercentMissing = sum(!is.na(Intensity))/ length(unique(dataset$Sample))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)
    
  #Half minimum value (per protein) imputation
  #We do a spread gather repeat to create rows because for some proteins there was not even a row hence we cant impute it.
  PCA_DF <-
  dataset %>% 
    dplyr::filter(ID %in% ProteinsToKeep$ID) %>%
    group_by(ID) %>%
    spread(key = "ID", value = "Intensity") %>%
    gather(key = "ID", value = "Intensity", unique(ProteinsToKeep$ID)) %>%
    mutate(IntensImputed = replace_na(Intensity, mean(Intensity, na.rm = T)/2)) %>%
    mutate(SampleDX = paste0(Sample,"/", DX, "/", Dataset)) %>%
    dplyr::select(ID, SampleDX, IntensImputed) %>%
    spread(key = "ID", value = "IntensImputed") %>%
    column_to_rownames("SampleDX")

  #scale and PCA
  PCA_DF_Results <- prcomp(as.matrix(PCA_DF))
  eigs <- PCA_DF_Results$sdev^2
  variance_percentage <- (eigs / sum(eigs))*100
  pc1var <- round(variance_percentage[1],digits=0)
  pc2var <- round(variance_percentage[2],digits=0)
  
  #Plot
  plot1 <- data.frame(PCA_DF_Results$x) %>%
    rownames_to_column() %>%
    separate(rowname, c("Sample", "DX", "Dataset"), "/") %>%
    ggplot(aes(x = PC1, y = PC2, fill = Dataset)) +
    geom_point(size = 3, shape = 21) +
    theme_pubr() +
    theme(text = element_text(family="serif")) +
    xlim(-100, 100) +
    ylim(-100, 50) +
    scale_fill_few("Dark") +
    xlab(paste('PC1',' (',pc1var,'% variance)',sep='')) +
    ylab(paste('PC2',' (',pc2var,'% variance)',sep='')) 
  
  
  #Half minimum value (per protein) imputation
  #We do a spread gather repeat to create rows because for some proteins there was not even a row hence we cant impute it.
  PCA_DF <-
  dataset2 %>% 
    dplyr::filter(ID %in% ProteinsToKeep$ID) %>%
    group_by(ID) %>%
    spread(key = "ID", value = "Z_score") %>%
    gather(key = "ID", value = "Z_score", unique(ProteinsToKeep$ID)) %>%
    mutate(IntensImputed = replace_na(Z_score, mean(Z_score, na.rm = T)/2)) %>%
    mutate(SampleDX = paste0(Sample,"/", DX, "/", Dataset)) %>%
    dplyr::select(ID, SampleDX, IntensImputed) %>%
    spread(key = "ID", value = "IntensImputed") %>%
    column_to_rownames("SampleDX")

  #scale and PCA
  PCA_DF_Results <- prcomp(as.matrix(PCA_DF))
  eigs <- PCA_DF_Results$sdev^2
  variance_percentage <- (eigs / sum(eigs))*100
  pc1var <- round(variance_percentage[1],digits=0)
  pc2var <- round(variance_percentage[2],digits=0)
  
  #Plot
  plot2 <- data.frame(PCA_DF_Results$x) %>%
    rownames_to_column() %>%
    separate(rowname, c("Sample", "DX", "Dataset"), "/") %>%
    ggplot(aes(x = PC1, y = PC2, fill = Dataset)) +
    geom_point(size = 3, shape = 21) +
    theme_pubr() +
    theme(text = element_text(family="serif")) +
    xlim(-100, 100) +
    ylim(-100, 50) +
    scale_fill_few("Dark") + 
    xlab(paste('PC1',' (',pc1var,'% variance)',sep='')) +
    ylab(paste('PC2',' (',pc2var,'% variance)',sep='')) 
   
  plot(ggarrange(plot1, plot2, common.legend = T, legend = T))
   
}

PCA_PLOT_BeforeAfter <- PCA_PLOT(Allproteinclinical , Allproteinclinical_Zscored)
```
## Mann-Whitney combined Dataset
Apply 70% cut off, run a mann-whitney test with Benjamini Hochberg Correction.
```{r, Volcano_combined, warning=FALSE, class.source = 'fold-hide', fig.width=6, fig.height=6}

Allproteinclinical_Zscored <- Allproteinclinical_Zscored %>%
   mutate(SampleDX = paste0(Sample,"/", DX, "/", Dataset))

ProteinsToKeep_all <- Allproteinclinical_Zscored %>%
    group_by(ID) %>%
    summarise(PercentMissing = sum(!is.na(Z_score))/ length(unique(Allproteinclinical_Zscored$SampleDX))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)

Tttest_all <- Allproteinclinical_Zscored %>%
  dplyr::filter(ID %in% ProteinsToKeep_all$ID) %>%
    drop_na(Z_score) %>%
    drop_na(DX) %>%
    group_by(ID) %>%
    wilcox_test(Z_score ~ DX, detailed = T) %>%
    adjust_pvalue(method = "BH") %>%
  mutate(SIGNIFICANT = p.adj < 0.05) %>%
  mutate(log10_padj = -1*log10(p.adj))

Tttest_all <- Tttest_all %>%
  separate(ID, c("UniProt", "Gene"), remove = F)
  
VolcanoAll <- Tttest_all %>%
  ggplot(aes(x = estimate, y = log10_padj, fill = SIGNIFICANT)) + 
  theme(text = element_text(family="serif")) +
  geom_point(size = 3, shape = 21) +
  geom_text_repel(aes(label = Gene), data = Tttest_all[Tttest_all$p.adj < 0.05,], box.padding = 0.5, max.overlaps = Inf) +
  scale_fill_manual(values = c("darkgrey", "darkred")) +
  theme_pubr() +
  geom_hline(yintercept = 1.3, linetype = 2, alpha = 0.7) +
    xlim(-2.2,2.2)+
    xlab("Z-score") +
    ylab("-log10(adjusted p-value)") +
  theme(legend.position= "none") 

plot(VolcanoAll)

Tttest_allDT <- Tttest_all %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)


# put CSV, XLS, and PDF in a collection
DT::datatable(Tttest_allDT, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

## Heatmap before cut off, after Cut off and significant
To illustrate the effect of the 70% cut off filter we make a heatmap of the whole dataset before and after 70% cut off filter.

### Before Cut off
Ordered for Dataset
```{r, heatmap before , warning=FALSE, message=FALSE, class.source = 'fold-hide'}
SuperHeatmap <- Allproteinclinical_Zscored %>%
  dplyr::select(ID, Sample, Dataset, DX, Z_score) %>%
  spread(key = "ID", value = "Z_score") %>%
  arrange(Dataset)


Heatmap(as.matrix(SuperHeatmap[4:ncol(SuperHeatmap)]),
        cluster_rows = F,
        cluster_columns = F,
        show_column_names = F,
        left_annotation = rowAnnotation(Dataset = SuperHeatmap$Dataset, col = list(Dataset = c("Barucker" = "#265DAB",
                                                                                               "Dayon" = "#DF5C24",
                                                                                               "In-house" = "#059748",
                                                                                               "Khoonsari" = "#E5126F",
                                                                                               "Lleó" = "#9D722A",
                                                                                               "Sathe" = "#7B3A96",
                                                                                               "Wang" = "#C7B42E"))),
        right_annotation = rowAnnotation(DX = SuperHeatmap$DX, col = list(DX = c("AD" = "darkred", "C" = "darkgrey"))))
```


### After Cut off
Ordered for Dataset.
```{r, heatmap after , warning=FALSE, message=FALSE, class.source = 'fold-hide'}
SuperHeatmap <- Allproteinclinical_Zscored %>%
    filter(ID %in% ProteinsToKeep_all$ID) %>%
  dplyr::select(ID, Sample, Dataset, DX, Z_score) %>%
  spread(key = "ID", value = "Z_score") %>%
  arrange(Dataset)


Heatmap(as.matrix(SuperHeatmap[4:ncol(SuperHeatmap)]),
        cluster_rows = F,
        cluster_columns = F,
        show_column_names = F,
        left_annotation = rowAnnotation(Dataset = SuperHeatmap$Dataset, col = list(Dataset = c("Barucker" = "#265DAB",
                                                                                               "Dayon" = "#DF5C24",
                                                                                               "In-house" = "#059748",
                                                                                               "Khoonsari" = "#E5126F",
                                                                                               "Lleó" = "#9D722A",
                                                                                               "Sathe" = "#7B3A96",
                                                                                               "Wang" = "#C7B42E"))),
        right_annotation = rowAnnotation(DX = SuperHeatmap$DX, col = list(DX = c("AD" = "darkred", "C" = "darkgrey"))))
```

### Filtering for only the significant. 
Ordered for both Dataset and DX.
```{r, heatmap signficant , warning=FALSE, message=FALSE, class.source = 'fold-hide'}
SignificantHits <- Tttest_all %>%
  dplyr::filter(SIGNIFICANT == T)

SuperHeatmap <- Allproteinclinical_Zscored %>%
    filter(ID %in% SignificantHits$ID) %>%
  dplyr::select(ID, Sample, Dataset, DX, Z_score) %>%
  spread(key = "ID", value = "Z_score") %>%
  arrange(Dataset)


Heatmap(as.matrix(SuperHeatmap[4:ncol(SuperHeatmap)]),
        cluster_rows = F,
        cluster_columns = F,
        show_column_names = T,
        left_annotation = rowAnnotation(Dataset = SuperHeatmap$Dataset, col = list(Dataset = c("Barucker" = "#265DAB",
                                                                                               "Dayon" = "#DF5C24",
                                                                                               "In-house" = "#059748",
                                                                                               "Khoonsari" = "#E5126F",
                                                                                               "Lleó" = "#9D722A",
                                                                                               "Sathe" = "#7B3A96",
                                                                                               "Wang" = "#C7B42E"))),
        right_annotation = rowAnnotation(DX = SuperHeatmap$DX, col = list(DX = c("AD" = "darkred", "C" = "darkgrey"))))

SuperHeatmap <- Allproteinclinical_Zscored %>%
    filter(ID %in% SignificantHits$ID) %>%
  dplyr::select(ID, Sample, Dataset, DX, Z_score) %>%
  spread(key = "ID", value = "Z_score") %>%
  arrange(DX)


Heatmap(as.matrix(SuperHeatmap[4:ncol(SuperHeatmap)]),
        cluster_rows = F,
        cluster_columns = F,
        show_column_names = T,
        left_annotation = rowAnnotation(Dataset = SuperHeatmap$Dataset, col = list(Dataset = c("Barucker" = "#265DAB",
                                                                                               "Dayon" = "#DF5C24",
                                                                                               "In-house" = "#059748",
                                                                                               "Khoonsari" = "#E5126F",
                                                                                               "Lleó" = "#9D722A",
                                                                                               "Sathe" = "#7B3A96",
                                                                                               "Wang" = "#C7B42E"))),
        right_annotation = rowAnnotation(DX = SuperHeatmap$DX, col = list(DX = c("AD" = "darkred", "C" = "darkgrey"))))
```


## Heatmap Combined vs. Single.
Join all the dataframes for the siginificant proteins in the combined dataset to compare with the statistics of single datasets.
```{r, joined Heatmap, class.source = 'fold-hide'}
SignificantHits <- Tttest_all %>%
  dplyr::filter(SIGNIFICANT == T)

HeatmapDF <- left_join(
    left_join(
      left_join(
        left_join(
          left_join(
            left_join(Dayon_ttest %>%
            filter(ID %in% SignificantHits$ID) %>%
            separate(ID, c("UniProt", "Gene"), remove = F) %>%
            mutate(Dayon = -1*log10(as.numeric(p.adj))) %>%
            dplyr::select(Gene, Dayon),
            sathe_ttest %>%
            filter(ID %in% SignificantHits$ID) %>%
            separate(ID, c("UniProt", "Gene"), remove = F) %>%
            mutate(Sathe = -1*log10(as.numeric(p.adj))) %>%
            dplyr::select(Gene, Sathe),
            by = c("Gene" = "Gene")),
            khoonsari_ttest %>%
            filter(ID %in% SignificantHits$ID) %>%
            separate(ID, c("UniProt", "Gene"), remove = F) %>%
            mutate(Khoonsari = -1*log10(as.numeric(p.adj))) %>%
            dplyr::select(Gene, Khoonsari),
          by = c("Gene" = "Gene")),
            multhaup_ttest %>%
            filter(ID %in% SignificantHits$ID) %>%
            separate(ID, c("UniProt", "Gene"), remove = F) %>%
            mutate(Barucker = -1*log10(as.numeric(p.adj))) %>%
            dplyr::select(Gene, Barucker),
          by = c("Gene" = "Gene")),
    wang_ttest %>%
    filter(ID %in% SignificantHits$ID) %>%
    separate(ID, c("UniProt", "Gene"), remove = F) %>%
    mutate(Wang = -1*log10(as.numeric(p.adj))) %>%
    dplyr::select(Gene, Wang),
  by = c("Gene" = "Gene")),
    omar_ttest %>%
    filter(ID %in% SignificantHits$ID) %>%
    separate(ID, c("UniProt", "Gene"), remove = F) %>%
    mutate(In_house = -1*log10(as.numeric(p.adj))) %>%
    dplyr::select(Gene, In_house),
  by = c("Gene" = "Gene")),
    Tttest_all %>%
    filter(ID %in% SignificantHits$ID) %>%
    separate(ID, c("UniProt", "Gene"), remove = F) %>%
    mutate(Meta = -1*log10(as.numeric(p.adj))) %>%
    dplyr::select(Gene, Meta),
  by = c("Gene" = "Gene")) %>%
  arrange(Gene = desc(Meta)) %>%
  column_to_rownames("Gene")

col_fun = colorRamp2(c(0, 1.3, 4, 8), c("white","#E6AC0E", "#DE4203", "#840602"))
lgd = Legend(col_fun = col_fun, title = "-log10(adjusted p-value)")
Heatmap_ALL <- Heatmap(as.matrix(HeatmapDF),
        col = col_fun,
        cluster_rows = F,
        cluster_columns = F,
        row_names_side = c("left"),
        rect_gp = gpar(col = "black", lwd = 2.5),
        width = ncol(HeatmapDF)*unit(5, "mm"),
        height = nrow(HeatmapDF)*unit(5, "mm"),
        heatmap_legend_param = list(title = "-log10(adjusted p value)",
                                    legend_height = unit(4, "cm"),
                                    title_position = "lefttop-rot"))

plot(Heatmap_ALL)
```


## msgidb Hallmark Enrichment
Use the msgidb Hallmark enrichment dataset to see what proteins are affected in our combined dataset.
```{r, Hallmark, class.source = 'fold-hide'}
SignificantHits <- Tttest_all %>% 
  dplyr::filter(SIGNIFICANT == T) 

all_gene_sets = msigdbr(species = "Homo sapiens", category = "H")
msigdbr_t2g = all_gene_sets %>%
  dplyr::distinct(gs_name, gene_symbol) %>%
  mutate(gs_name = str_remove_all(gs_name, "HALLMARK_")) %>% #REMOVE ALL THE HALLMARK STUFF
  as.data.frame()

enrichResults <- enricher(gene = SignificantHits$Gene, TERM2GENE = msigdbr_t2g)

#clusterProfiler::dotplot(enrichResults)

HallMarkPlot <- cnetplot(enrichResults, cex_category = 2, cex_label_category = 1, cex__label_gene = 1) +
  scale_color_manual(values = c("#3B9AB2", "#F21A00")) +
  theme(legend.position = "none") +
  theme(text = element_text(family="serif")) 
  
plot(HallMarkPlot)
```

## KEGG Enrichment
Use the KEGG enrichment dataset to see what proteins are affected in our combined dataset.
```{r, kegg enrichment, warning=FALSE, class.source = 'fold-hide'}
#Enrich for each colour
enrichtments <- enrichR::enrichr(SignificantHits$Gene,
                              c("KEGG_2021_Human"))

myPalette <-colorRampPalette(rev(RColorBrewer::brewer.pal(11, "Spectral")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(0.0, 0.02))

KeggPlot <- enrichtments$KEGG_2021_Human %>%
  slice_head(n = 10) %>%
  mutate_at("Term", str_trunc, width = 45) %>%
  dplyr::select(Term, Genes, Adjusted.P.value, Overlap) %>%
  mutate(KeggPathway = fct_reorder(Term, Adjusted.P.value, .desc = T)) %>%
  separate(Overlap, c("Count", "All")) %>%
  mutate(GeneRatio = as.numeric(Count)/ as.numeric(All)) %>%
  mutate(Count = as.numeric(Count)) %>%
  ggplot(aes(x = GeneRatio, y = KeggPathway, colour = Adjusted.P.value, )) +
  geom_point(aes(size=Count)) +
  scale_colour_gradient(low = "red", high = "darkblue") +
  theme_pubr() +
  theme(legend.position = "right") +
  theme(text = element_text(family="serif"))
  
plot(KeggPlot)


```
## Enrichtments
```{r, fig.width=15, fig.height=15}
library(org.Hs.eg.db)
library(enrichplot)
library(DOSE)
dataKathrin <- Tttest_all %>% 
  dplyr::filter(SIGNIFICANT == T) %>%
  dplyr::select(Gene)

#convert GENE NAME (SYMBOL) to ENTREZ ID 
data_Genes_list_ENTREZID <- mapIds(org.Hs.eg.db, dataKathrin$Gene, 'ENTREZID', 'SYMBOL')

data_ID <- data.frame(matrix(ncol=4,nrow=length(data_Genes_list_ENTREZID), dimnames=list(NULL, c("Entrez", "Gene", "Direction", "Disease"))))

data_ID$Entrez <- data_Genes_list_ENTREZID
data_ID$Gene <- dataKathrin$Gene
data_ID <- data_ID %>% drop_na(Entrez)


#fun: One of "groupGO", "enrichGO", "enrichKEGG", "enrichDO" or "enrichPathway" .
xx <- enrichGO(gene=data_ID$Entrez, 
                     pvalueCutoff=0.05,
                     OrgDb = "org.Hs.eg.db", #for GO only
                     ont="BP",               #for GO only "CC" "MF"  
                     #readable = TRUE,
                     pAdjustMethod = "BH",
                     qvalueCutoff = 0.05
                     )

#create output and threshold
myfavourite_enrichment <- data.frame(xx@result)
myfavourite_enrichment_p <- myfavourite_enrichment  %>% filter(pvalue <0.05)
myfavourite_enrichment_padj <- myfavourite_enrichment  %>% filter(p.adjust <0.05)
xx_padj<- xx  %>% filter(p.adjust <0.05)
xx_p<- xx  %>% filter(pvalue <0.05)


#plot network based on gene overlap of TOPX pathways
xx_padj2 <- pairwise_termsim(xx_padj) 

#ONLY FOR Biolgocial Processes
xx_padj3 <- clusterProfiler::simplify(xx_padj2, cutoff = 0.38, by = "p.adjust", select_fun=min)

emapplot(xx_padj3,
         #showCategory=100,
         pie="count", 
         cex_category=2,
         cex_line=1,
         layout="kk",
         colorEdge = TRUE,
         cex_label_category = 1.1,
         colorEdge="black") +
  ggtitle("GO - Biological Processes")
```


# 2. Pruning
This dataset (10 AD, 10 Control) was created in-house.

### Normalization
We determine the summed intensity (un-transformed) of each sample.
We take the median value of all those summed intensities and use that for normalization.
```{r, Pruning dataset normalize, class.source = 'fold-hide'}
Zetterberg_medianSummedIntensity <- mean((
  Zetterberg_protein_clean %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  group_by(Sample) %>%
  summarise(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  ungroup() %>%
  summarise(medianOfSummedIntensities = median(PerSampleSum)))$medianOfSummedIntensities)

Zetterberg_protein_normalized <-   
Zetterberg_protein_clean %>%
  group_by(Sample) %>%
  mutate(PerSampleSum = sum(Intensity, na.rm = TRUE)) %>%
  mutate(NormalizeFactor = Zetterberg_medianSummedIntensity/ PerSampleSum) %>%
  mutate(Intensity = Intensity * NormalizeFactor) %>%
  ungroup() %>%
  dplyr::select(ID, Sample, Intensity) %>%
  mutate_all(~replace(., . == 0, NA)) %>%
  mutate(Intensity = log2(Intensity))
```

### Outlier Selection
```{r, Pruning dataset add clinical, warning=FALSE, class.source = 'fold-hide'}
#Add with Clinical
Zetterberg_protein_normalized <- Zetterberg_protein_normalized %>%
  separate(Sample, c("first", "second", "third", "fourth", "Sample")) %>%
  dplyr::select(ID, Sample, Intensity)

Zetterberg_Clinical <- read_excel("Datasets/Zetterberg_Clinical.xlsx")

Zetterbergproteinclinical <- left_join(Zetterberg_Clinical, Zetterberg_protein_normalized, by = c("Sample" = "Sample")) %>%
  dplyr::select(ID, Sample, DX, Intensity)

Zetterbergproteinclinical_NO <- OutlierRemover(Zetterbergproteinclinical, "Pruning Dataset")
```

### Mann-Whitney Test
```{r, volcano pruning, warning=FALSE, class.source = 'fold-hide', fig.width=6, fig.height=6}
Ttest_AD_Zscore <- function(dataset){
  #70% cut off
  ProteinsToKeep <- dataset %>%
    group_by(ID) %>%
    summarise(PercentMissing = sum(!is.na(Z_score))/ length(unique(dataset$Sample))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)

  dataset_ttest <- dataset %>%
    filter(ID %in% ProteinsToKeep$ID) %>%
    drop_na(Z_score) %>%
    drop_na(DX) %>%
    group_by(ID) %>%
    wilcox_test(Z_score ~ DX, detailed = T) %>%
    adjust_pvalue(method = "BH") %>%
    mutate(SIGNIFICANT = p.adj < 0.05) %>%
  mutate(log10_padj = -1*log10(p.adj))
  
  return(dataset_ttest)
}
Zetterbergproteinclinical_NO$Dataset <- "Pruning"
Zetterbergproteinclinical_Zscore <- Z_Scorer(Zetterbergproteinclinical_NO)
Zetterberg_ttest <- Ttest_AD_Zscore(Zetterbergproteinclinical_Zscore)
  
Zetterberg_ttest <- Zetterberg_ttest %>%
  separate(ID, c("UniProt", "Gene"), remove = F)

VolcanoPruning <- Zetterberg_ttest %>%
  ggplot(aes(x = estimate, y = log10_padj, fill = SIGNIFICANT)) + 
  geom_point(size = 3, shape = 21) +
  geom_text_repel(aes(label = Gene), data = Zetterberg_ttest[Zetterberg_ttest$p.adj < 0.05,], max.overlaps = Inf) +
  scale_fill_manual(values = c("darkgrey", "darkred")) +
  xlim(-6,6) +
  theme_pubr() +
  geom_hline(yintercept = 1.3, linetype = 2, alpha = 0.7) +
    #xlim(-2.6,2.6)+
    xlab("Z-score") +
    ylab("-log10(adjusted p-value)") +
  theme(legend.position= "none") +
  theme(text = element_text(family="serif"))

plot(VolcanoPruning)

Zetterberg_ttestDT <- Zetterberg_ttest %>%
  dplyr::mutate(FC = estimate) %>%
  dplyr::select(ID, FC, p, p.adj)


# put CSV, XLS, and PDF in a collection
DT::datatable(Zetterberg_ttestDT, extensions = 'Buttons', options = list(dom = 'Bfrtip', buttons = list('copy', 'print', list(extend = 'collection',
        buttons = c('csv', 'excel'),text = 'Download' ))))
```

### Venny of All vs Pruning
```{r, venny prune all,  class.source = 'fold-hide'}
PruningSignificant <- Zetterberg_ttest %>%
  filter(p.adj < 0.05)

VennyPruneMeta <- plot(euler(list(
      "Pruning" = PruningSignificant$Gene,
      "Discovery" = SignificantHits$Gene),
    shape = "ellipse"), quantities = T,
    fills = c("#FC4E07", "#E7B800")
)

plot(VennyPruneMeta)

```

### BoxPlots Pruning
We select the three overlapping Markers and visualize in boxplot.
```{r, boxplotpruning, warning=FALSE, class.source = 'fold-hide'}
Comparisons <- list(c("AD" , "C"))

Pruning_BoxPlot <- 
  Zetterbergproteinclinical_Zscore %>%
  separate(ID, c("UniProt", "Gene"), remove = F) %>%
  filter(ID %in% c("P04075_ALDOA", "P14618_PKM", "P07195_LDHB")) %>%
  ggplot(aes(DX, Z_score)) +
  geom_boxplot(aes(fill = Gene, alpha = DX)) +
  facet_wrap(. ~ Gene) +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("#1ca375", "#827d9c", "#d15b01")) +
  theme_pubr() +
  ylim(-2, 10)+
  ylab("Z-score") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif"))
plot(Pruning_BoxPlot)
```


# 3. Validation
We will use two recent large-scale CSF proteomics datasets that are available. Those datasets were downloaded through the publications Supplementary data respositories. We import them here.
```{r, import validation, warning=FALSE, class.source = 'fold-hide'}
Seyfried_DF <- read_excel("Datasets/Seyfried_resultmatrix.xlsx")
Seyfried_DF[Seyfried_DF == 0] <- NA
Mann_DF <- read_excel("Datasets/Mann_Matrix.xlsx")
Mann_DF[Mann_DF == 0] <- NA
```


## Johnson Data
Study used DDA TMT on a large cohort (Emory University, USA).

#### Prepare Johnson Data
Long format it, add AD vs. Control information based on sample names.
```{r, prepare Johnson, warning=FALSE, message=FALSE, class.source = 'fold-hide'}
##### SEYFRIED PREPARE
cl <- colnames(Seyfried_DF[2:ncol(Seyfried_DF)])

Seyfried_resultmatrix <-  Seyfried_DF %>%
  gather(cl, key = "Sample", value = "Intensity") 

Seyfried_resultmatrix$DX <- grepl("Co", Seyfried_resultmatrix$Sample, fixed = T)

```

#### Boxplots of biomarker candidates 
```{r, boxplot Johnson, warning=FALSE, class.source = 'fold-hide'}
Seyfried_BoxPlot <- 
  Seyfried_resultmatrix %>%
    filter(rowID %in% c("P04075", "P14618", "P07195")) %>%
  mutate(Gene = ifelse(rowID == "P04075", "ALDOA", ifelse(rowID == "P14618", "PKM","LDHB"))) %>%
  mutate(DX = ifelse(DX == TRUE, "C","AD")) %>% 
  ggplot(aes(DX, Intensity)) +
  geom_boxplot(aes(fill = Gene, alpha = DX)) +
  facet_wrap(. ~ Gene) +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("#1ca375", "#827d9c", "#d15b01")) +
  theme_pubr() +
  ylim(-1, 1.5) +
  ylab("Ratio") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif"))

plot(Seyfried_BoxPlot)
```


## Bader Data
Study used LFQ DIA on CSF samples from three cohorts. 

#### Prepare Bader Data
Long format it, add AD vs. Control information based on sample names.
This dataset contains a few (17) isoforms. We average them for downstream analysis.
```{r, prepare Bader, warning=FALSE, message=FALSE, class.source = 'fold-hide'}
cl_mann <- colnames(Mann_DF[2:ncol(Mann_DF)])

Mann_resultmatrix <- Mann_DF %>%
  gather(cl_mann, key = "Sample", value = "Intensity") %>%
  mutate(Intensity = log2(Intensity))

Mann_resultmatrix$DX <- grepl("Co", Mann_resultmatrix$Sample, fixed = T)

#There is 17 proteins in this dataset where isoforms are specified.
#To make this data easily applicable to all the others, we average it.
Mann_resultmatrix <- Mann_resultmatrix %>%
  group_by(Sample, rowID, DX) %>%
  summarise(Intensity = mean(Intensity)) 
```

#### Boxplots of biomarker candidates 
```{r, boxplot Bader, warning=FALSE, class.source = 'fold-hide'}
Mann_BoxPlot <- 
  Mann_resultmatrix %>%
  filter(rowID %in% c("P04075", "P14618", "P07195")) %>%
  mutate(Gene = ifelse(rowID == "P04075", "ALDOA", ifelse(rowID == "P14618", "PKM","LDHB"))) %>%
  mutate(DX = ifelse(DX == TRUE, "C","AD")) %>% 
  ggplot(aes(DX, Intensity)) +
  geom_boxplot(aes(fill = Gene, alpha = DX)) +
  facet_wrap(. ~ Gene) +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("#1ca375", "#827d9c", "#d15b01")) +
  theme_pubr() +
  ylim(17.5, 21.5) +
  ylab("log2(Intensity)") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif"))

plot(Mann_BoxPlot)
```

## Biomarker Model Development

Using Logistic Regression we develop biomarker panels of the three selected biomarker candidates. We develop a model based on the Johnson Data, and another model on the Seyfried Data. Each model is then tested on both the Johnson and Bader Data. If a model is effective in both datasets we may assume the results is not due to overfitting.

### Model Development 

#### Develop Model Johnson
```{r, model Johnson , warning=FALSE, class.source = 'fold-hide'}
Seyfried_ModelDF <- Seyfried_resultmatrix %>%
 dplyr::filter(rowID %in% c("P04075", "P14618", "P07195")) %>%
  dplyr::select(Sample, 'rowID', DX, Intensity) %>%
  spread(key = "rowID", value = "Intensity")

Seyfried_ModelDF <- data.frame(Seyfried_ModelDF)
Seyfried_ModelDF$DX <- as.factor(Seyfried_ModelDF$DX)

#Create the Model
Seyfried_MarkerPanel <- glm(DX ~ P04075 + P14618 + P07195, data = Seyfried_ModelDF, family = 'binomial')
```


#### Develop Model Bader
```{r, model Bader, warning=FALSE, class.source = 'fold-hide'}
Mann_ModelDF <- Mann_resultmatrix %>%
 dplyr::filter(rowID %in% c("P04075", "P14618", "P07195")) %>%
  dplyr::select(Sample, 'rowID', DX, Intensity) %>%
  spread(key = "rowID", value = "Intensity")

Mann_ModelDF$DX <- as.factor(Mann_ModelDF$DX)

#Create the Model
Mann_MarkerPanel <- glm(DX ~ P04075 + P14618 + P07195, data = Mann_ModelDF, family = 'binomial')
```

### Model Testing

#### Johnson Data

We observe a similair AUROC for the two models. We can thus assume that the three markers are effective at differentiating AD from Controls, indepedent from potential overfitting.

```{r, roc plot johnson, warning=FALSE, message=FALSE, class.source = 'fold-hide'}
Seyfried_ModelDF$Seyfried_panel <- predict(Seyfried_MarkerPanel, Seyfried_ModelDF)
Seyfried_ModelDF$Mann_panel <- predict(Mann_MarkerPanel, Seyfried_ModelDF)

Mann_ModelDF$Mann_panel <- predict(Mann_MarkerPanel, Mann_ModelDF)
Mann_ModelDF$Seyfried_panel <- predict(Seyfried_MarkerPanel, Mann_ModelDF)

seyfried_seyfriedmodel <- roc(DX ~ Seyfried_panel, Seyfried_ModelDF)
seyfried_mannmodel <- roc(DX ~ Mann_panel, Seyfried_ModelDF)
seyfried_ALDOA <- roc(DX ~ P04075, Seyfried_ModelDF)
seyfried_PKM <- roc(DX ~ P14618, Seyfried_ModelDF)
seyfried_LDHB <- roc(DX ~ P07195, Seyfried_ModelDF)

ROC_SEYFRIED <- ggroc(list("ALDOA (0.85)" = seyfried_ALDOA,
           "PKM (0.82)" = seyfried_PKM,
           "LDHB (0.79)" = seyfried_LDHB,
           "Model Bader (0.87)" = seyfried_mannmodel,
           "Model Johnson (0.87)" = seyfried_seyfriedmodel), lwd = 1.5) +
  scale_color_brewer(palette = "Dark2") + 
  theme_pubr() +
  theme(legend.position = "right",
       text = element_text(family="serif")) +
  coord_fixed()

plot(ROC_SEYFRIED)
```

#### Bader Data


Again, we observe a similair AUROC for the two models. We can thus assume that the three markers are effective at differentiating AD from Controls, indepedent from potential overfitting.
```{r, rocplot bader, warning=FALSE, message=FALSE, class.source = 'fold-hide'}
Mann_seyfriedmodel <- roc(DX ~ Seyfried_panel, Mann_ModelDF)
Mann_mannmodel <- roc(DX ~ Mann_panel, Mann_ModelDF)
Mann_ALDOA <- roc(DX ~ P04075, Mann_ModelDF)
Mann_PKM <- roc(DX ~ P14618, Mann_ModelDF)
Mann_LDHB <- roc(DX ~ P07195, Mann_ModelDF)

ROC_MANN <- ggroc(list("ALDOA (0.81)" = Mann_ALDOA,
           "PKM (0.78)" = Mann_PKM,
           "LDHB (0.68)" = Mann_LDHB,
           "Model Bader (0.82)" = Mann_mannmodel,
           "Model Johnson (0.82)" = Mann_seyfriedmodel), lwd = 1.5) +
  scale_color_brewer(palette = "Dark2") + 
  theme_pubr() +
  theme(legend.position = "right",
       text = element_text(family="serif"), aspect.ratio=1)

plot(ROC_MANN)
```

# 4. Additional Analyses.

There was some additional analyses throughout the manuscript. Here they are described.

### Clinical Extra Data



```{r, warning=FALSE, class.source = 'fold-hide'}
Seyfried_clinical <- read_csv("Datasets/0.Traits.csv")
Seyfried_DF_long <- Seyfried_DF %>%
  gather(colnames(Seyfried_DF)[2:ncol(Seyfried_DF)], key = "Sample", value = "Intensity") %>%
  separate(Sample, into = c("Sample", "X"), sep = "_") %>%
  dplyr::select(Sample, rowID, Intensity)


Seyfried_both <- inner_join(Seyfried_clinical, Seyfried_DF_long, b = c("SampleID" = "Sample"))

Seyfried_both_selected <- Seyfried_both %>%
  filter(rowID %in% c("P04075", "P14618", "P07195")) %>%
  tidyr::spread("rowID", "Intensity") %>%
  mutate(Group = factor(Group))

Seyfried_both_selected_panel3 <- glm(Group ~ P04075 + P14618 + P07195, data = Seyfried_both_selected, family = 'binomial')
Seyfried_both_selected_tauAB3 <- glm(Group ~ AB42.ELISA + tTau.ELISA + pTau.ELISA, data = Seyfried_both_selected, family = 'binomial')
Seyfried_both_selected_all6 <- glm(Group ~ P04075 + P14618 + P07195 + AB42.ELISA + tTau.ELISA + pTau.ELISA, data = Seyfried_both_selected, family = 'binomial')

Seyfried_both_selected$panel3 <- predict(Seyfried_both_selected_panel3, Seyfried_both_selected)
Seyfried_both_selected$tauAB3 <- predict(Seyfried_both_selected_tauAB3, Seyfried_both_selected)
Seyfried_both_selected$all6 <- predict(Seyfried_both_selected_all6, Seyfried_both_selected)

roc(Group ~ P04075, Seyfried_both_selected)
roc(Group ~ P07195, Seyfried_both_selected)
roc(Group ~ P14618, Seyfried_both_selected)
roc(Group ~ AB42.ELISA, Seyfried_both_selected)
roc(Group ~ tTau.ELISA, Seyfried_both_selected)
roc(Group ~ pTau.ELISA, Seyfried_both_selected)
roc(Group ~ panel3, Seyfried_both_selected)
roc(Group ~ tauAB3, Seyfried_both_selected)
roc(Group ~ all6, Seyfried_both_selected)

Seyfried_both_selected_cor <- Seyfried_both_selected %>%
  dplyr::select(- SampleID, -Batch, -GUID, -Group, -Sex, -Race, -APOE.Genotype) %>%
  mutate(ALDOA = P04075,
         PKM = P14618,
         LDHB = P07195) %>%
  dplyr::select(AB42.ELISA, tTau.ELISA, pTau.ELISA, ALDOA, PKM, LDHB)

corrplot::corrplot(cor(Seyfried_both_selected_cor,
                       use = "pairwise.complete.obs",),
                   method = "number")

```

```{r, import validation, warning=FALSE, class.source = 'fold-hide'}
mann_clinical <- read_excel("Datasets/msb199356-sup-0004-datasetev2_PvZ.xlsx")
mann_clinical <- mann_clinical %>% 
  separate(samplename, into = c("Sample", "X", "xx", "xxx", "xxxx", "xxxxx"), sep = "_") %>%
  mutate(sample = paste0(Sample, "_", X)) %>%
  dplyr::select(sample, gender, tTau, pTau, AB42, AB40, DX, DX_CLINICAL)

Mann_resultmatrix_prepare <- Mann_resultmatrix %>%
  ungroup() %>%
  separate(Sample, into = c("Sample", "X", "xx"), sep = "_") %>%
  mutate(sample = paste0(Sample, "_", X)) %>%
  dplyr::select(sample, rowID, Intensity)

mann_both <- inner_join(mann_clinical, Mann_resultmatrix_prepare, b = c("sample" = "sample"))

mann_both_selected <- mann_both %>%
  filter(rowID %in% c("P04075", "P14618", "P07195")) %>%
  tidyr::spread("rowID", "Intensity") %>%ListOutliers
  mutate(DX = factor(DX))

mann_both_selected_panel3 <- glm(DX ~ P04075 + P14618 + P07195, data = mann_both_selected, family = 'binomial')
mann_both_selected_tauAB3 <- glm(DX ~ AB42 + tTau + pTau, data = mann_both_selected, family = 'binomial')
mann_both_selected_all6 <- glm(DX ~ P04075 + P14618 + P07195 + AB42 + tTau + pTau, data = mann_both_selected, family = 'binomial')

mann_both_selected$panel3 <- predict(mann_both_selected_panel3, mann_both_selected)
mann_both_selected$tauAB3 <- predict(mann_both_selected_tauAB3, mann_both_selected)
mann_both_selected$all6 <- predict(mann_both_selected_all6, mann_both_selected)



roc(DX ~ P04075, mann_both_selected)
roc(DX ~ P07195, mann_both_selected)
roc(DX ~ P14618, mann_both_selected)
roc(DX ~ AB42, mann_both_selected)
roc(DX ~ tTau, mann_both_selected)
roc(DX ~ pTau, mann_both_selected)
roc(DX ~ panel3, mann_both_selected)
roc(DX ~ tauAB3, mann_both_selected)
roc(DX ~ all6, mann_both_selected)

test <- Mann_resultmatrix %>%
  filter(rowID == "P07195")


mann_both_selected_cor <- mann_both_selected %>%
  mutate(ALDOA = P04075,
         PKM = P14618,
         LDHB = P07195) %>%
  dplyr::select(AB42, tTau, pTau, ALDOA, PKM, LDHB)

corrplot::corrplot(cor(mann_both_selected_cor,
                       use = "pairwise.complete.obs",),
                   method = "number")
```
### VENNY

```{r}
library(eulerr)
plot(euler(list(
      #"Down-Selection - 70% Cutoff" = unique(Zetterberg_ttest$ID),
      "Down-Selection" = unique(Zetterbergproteinclinical$ID),
      #"Meta-Analayis - no Cutoff" = unique(Allproteinclinical_Zscored$ID),
      "Meta-Analysis/Discovery" = unique(ProteinsToKeep_all$ID)
      ),
    shape = "ellipse"),
    quantities = T
)
```


#Reviewer stuff 2
```{r}
MANNPROT <- colnames(Mann_DF)[2:ncol(Mann_DF)]

MANNDATA <- Mann_DF %>%
  gather(MANNPROT, key = "SAMPLE", value = "INTENSITY") %>%
  separate(SAMPLE, sep = "_", into = c("Thing", "Sample", "DX")) %>%
  mutate(INTENSITY = log2(INTENSITY),
         DX = toupper(DX),
         sample = paste0(Thing, Sample)) %>%
group_by(rowID, sample) %>%
#filter(n() > 1) %>%
 mutate(INTENSITY = mean(INTENSITY, na.rm = T)) %>%
 slice(1) %>%
 ungroup()
  
MANNDATA_FILTER <- MANNDATA %>%
    group_by(rowID) %>%
    summarise(PercentMissing = sum(!is.na(INTENSITY)) / length(unique(MANNDATA$sample))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)

Seyfried_resultmatrix
Tttest_all_MANN <- MANNDATA %>%
  dplyr::filter(rowID %in% MANNDATA_FILTER$rowID) %>%
    drop_na(INTENSITY) %>%
    drop_na(DX) %>%
    group_by(rowID) %>%
    wilcox_test(INTENSITY ~ DX, detailed = T) %>%
    adjust_pvalue(method = "BH") %>%
  mutate(SIGNIFICANT = p.adj < 0.05) %>%
  mutate(log10_padj = -1*log10(p.adj))


  
JOHNSONDATA_FILTER <- Seyfried_resultmatrix %>%
    group_by(rowID) %>%
    summarise(PercentMissing = sum(!is.na(Intensity)) / length(unique(Seyfried_resultmatrix$Sample))) %>%
    mutate(remove = PercentMissing > 0.7) %>%
    dplyr::filter(remove == T)

Tttest_all_JOHNSON <- Seyfried_resultmatrix %>%
  dplyr::filter(rowID %in% JOHNSONDATA_FILTER$rowID) %>%
    drop_na(Intensity) %>%
    drop_na(DX) %>%
    group_by(rowID) %>%
    wilcox_test(Intensity ~ DX, detailed = T) %>%
    adjust_pvalue(method = "BH") %>%
  mutate(SIGNIFICANT = p.adj < 0.05) %>%
  mutate(log10_padj = -1*log10(p.adj))

top21 <- Tttest_all %>%
  filter(p.adj < 0.05) %>%
  separate(ID, sep = "_", into = c("Uniprot", "Gene")) %>%
  select(Uniprot, Gene, p, p.adj)

mann_top21 <- Tttest_all_MANN %>%
  filter(rowID %in% top21$Uniprot) %>%
  select(rowID, p, p.adj)

John_top21 <- Tttest_all_JOHNSON %>%
  filter(rowID %in% top21$Uniprot) %>%
  select(rowID, p, p.adj)

top21_all <- top21 %>%
  left_join(John_top21, by = c("Uniprot" = "rowID")) %>%
  left_join(mann_top21, by = c("Uniprot" = "rowID"))

write.csv(top21_all, "top21_all.csv")
```

# 21 proteins performance

```{r, fig.width=14, fig.height=5}

for (i in top21$Uniprot){

discovery_roc <- 
  Allproteinclinical_Zscored %>%
  filter(grepl(i, ID))
proteinname <- discovery_roc[1,1]

discovery_roc <- roc(discovery_roc$DX, discovery_roc$Z_score)

discovery_boxplot <- 
  Allproteinclinical_Zscored %>%
  filter(grepl(i, ID)) %>%
  mutate(Type = "Discovery") %>%
  ggplot(aes(x = DX, y = Z_score, fill = DX)) +
  geom_boxplot() +
  facet_wrap(~ Type) +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("grey", "white")) +
  theme_pubr() +
  #ylim(-1, 1.5) +
  ylab("Z-Score") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif"))

pruning_roc <- Zetterbergproteinclinical_Zscore %>%
    filter(grepl(i, ID)) %>% 
  drop_na()
if (nrow(pruning_roc) == 0){
  pruning_roc <- NULL
} else {
  pruning_roc <- roc(pruning_roc$DX, pruning_roc$Z_score)
}

try(Pruning_boxplot <- Zetterbergproteinclinical_Zscore %>%
    filter(grepl(i, ID)) %>%
  mutate(Type = "Pruning") %>%
  ggplot(aes(x = DX, y = Z_score, fill = DX)) +
  geom_boxplot() +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("orange", "white")) +
  theme_pubr() +
  facet_wrap(~ Type) +
  #ylim(-1, 1.5) +
  ylab("Z-Score") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif")))

mann_roc <- MANNDATA %>%
    filter(grepl(i, rowID)) %>%
  drop_na()
if (nrow(mann_roc) == 0){
  mann_roc <- NULL
} else {
  try(mann_roc <- roc(mann_roc$DX, mann_roc$INTENSITY))
}

try(mann_boxplot <- MANNDATA %>%
    filter(grepl(i, rowID)) %>%
  mutate(Type = "Bader et al.") %>%
  mutate(DX = ifelse(grepl("CO", DX), "C", "AD")) %>%
  ggplot(aes(x = DX, y = INTENSITY, fill = DX)) +
  geom_boxplot() +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("darkblue", "white")) +
  theme_pubr() +
  facet_wrap(~ Type) +
  #ylim(-1, 1.5) +
  ylab("log2(Intensity)") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif")))

seyfried_roc <- Seyfried_resultmatrix %>%
    filter(grepl(i, rowID)) %>%
  drop_na()
if (nrow(seyfried_roc) == 0){
  seyfried_roc <- NULL
} else {
  try(seyfried_roc <- roc(seyfried_roc$DX, seyfried_roc$Intensity))
}


try(seyfried_boxplot <- Seyfried_resultmatrix %>%
    filter(grepl(i, rowID)) %>%
  mutate(Type = "Johnson et al.") %>%
  mutate(DX = ifelse(grepl("Co", Sample), "C", "AD")) %>%
  ggplot(aes(x = DX, y = Intensity, fill = DX)) +
  geom_boxplot() +
  scale_alpha_discrete(range = c(1, 0)) +
  scale_fill_manual(values = c("darkred", "white")) +
  theme_pubr() +
  facet_wrap(~ Type) +
  #ylim(-1, 1.5) +
  ylab("TMT-Ratio") +
    theme(axis.title.x=element_blank(),
        legend.position = "none",
        text = element_text(family="serif")))

mytable <- cbind(Dataset=c("Discovery","Pruning","Johnson","Bader"),
                 AUROC = c(round(discovery_roc$auc,2),
                           NA,
                           NA,
                           NA))
                 # AUROC = c(round(discovery_roc$auc,2),
                 #           round(pruning_roc$auc,2),
                 #           round(seyfried_roc$auc,2),
                 #           round(mann_roc$auc,2)))

listggroc <- list("Discovery"=discovery_roc, "Pruning" = pruning_roc, "Johnson" = seyfried_roc, "Bader" = mann_roc)

if (!is.null(pruning_roc)){
  mytable[2,2] <- round(pruning_roc$auc,2)
} else {
  listggroc <- within(listggroc, rm(Pruning))
  Pruning_boxplot <- patchwork::plot_spacer()

}

if (!is.null(seyfried_roc)){
  mytable[3,2] <- round(seyfried_roc$auc,2)
} else {
  listggroc <- within(listggroc, rm(Johnson))
    seyfried_boxplot <- patchwork::plot_spacer()

}

if (!is.null(mann_roc)){
  mytable[4,2] <- round(mann_roc$auc,2)
} else {
    listggroc <- within(listggroc, rm(Bader))
      mann_boxplot <- patchwork::plot_spacer()

}

ggroc_plot <- 
  ggroc(listggroc, lwd = 2) +
  theme_pubr() +
  scale_color_manual(values = c("Johnson" = "darkred", "Bader" = "darkblue", "Discovery" = "grey", "Pruning" = "Orange"),
    name = "Dataset") +
  theme(legend.position = c(.5,.3)) +
    annotation_custom(tableGrob(mytable), xmin = -0.3, ymin=0.15, ymax=0.4)
  
format <- "
AABBEEE
CCDDEEE
"

GGPLOT <- discovery_boxplot + Pruning_boxplot + seyfried_boxplot + mann_boxplot + ggroc_plot + patchwork::plot_layout(design = format) +
  patchwork::plot_annotation(title = proteinname, theme = theme(plot.title = element_text(size = 25)))

ggsave(paste0("top21Plots/", i, ".png"), GGPLOT, width = 14, height = 4)

}

```
#Step AIC
```{r}
library(MASS)
Seyfried_stepaic_prepare <- Seyfried_resultmatrix %>%
  filter(rowID %in% top21$Uniprot) %>%
  spread(rowID, Intensity) %>%
  column_to_rownames("Sample") 
  
seyfried_stepaic <- glm(DX ~ . , family=binomial, data = Seyfried_stepaic_prepare) %>%
  stepAIC(direction = "backward")

mann_stepaic_prepare <- MANNDATA %>%
  filter(rowID %in% top21$Uniprot) %>%
  #mutate(INTENSITY = ifelse(INTENSITY == NaN, NA, INTENSITY)) %>%
  spread(rowID, INTENSITY) %>%
  dplyr::select(-Thing, -Sample, - sample) 
  mutate(DX = ifelse(DX == "CO", 0, 1))
  
mann_stepaic <- glm(DX ~ . , family=binomial, data = mann_stepaic_prepare) %>%
  stepAIC(direction = "backward")
```

#Try every Three Combination
```{r, warning=FALSE}
#Find Intersect of the 21 proteins significant that are found in BOTH seyfried and MANN data
topX_intersect <- base::intersect(unique(top21$Uniprot), unique(Seyfried_resultmatrix$rowID))
topX_intersect <- base::intersect(topX_intersect, unique(MANNDATA$rowID))

#Prepare the DF's
seyfried_model3_prepare <- Seyfried_resultmatrix %>%
  filter(rowID %in% topX_intersect) %>%
  spread(rowID, Intensity) %>%
  column_to_rownames("Sample") 

mann_model3_prepare <- MANNDATA %>%
  filter(rowID %in% topX_intersect) %>%
  #mutate(INTENSITY = ifelse(INTENSITY == NaN, NA, INTENSITY)) %>%
  spread(rowID, INTENSITY) %>%
  dplyr::select(-Thing, -Sample, - sample) %>%
  mutate(DX = ifelse(DX == "CO", 0, 1))
  
#Create results DF
three_way_aruocs <- data.frame(matrix(ncol = 5, nrow = 0))
colnames(three_way_aruocs) <- c("ThreeProt", "seyfried_data_seyfried_model", "seyfried_data_mann_model", "mann_data_seyfried_model", "mann_data_mann_model")
number <- 1
for (protein_1 in topX_intersect){
  for (protein_2 in topX_intersect){
    for (protein_3 in topX_intersect){
      
      if (protein_1 != protein_2 & protein_1 != protein_3 & protein_2 != protein_3){
      
        #Create Seyfried data model
        seyfried_model3_tempSelect <- seyfried_model3_prepare %>%
          dplyr::select(DX, protein_1, protein_2, protein_3) %>%
          drop_na()
        model_seyfried <- glm(DX ~ ., data = seyfried_model3_tempSelect, family = 'binomial')
        
        #create Mann data model
        mann_model3_tempSelect <- mann_model3_prepare %>%
          dplyr::select(DX, protein_1, protein_2, protein_3) %>%
          drop_na()
        model_mann <- glm(DX ~ ., data = mann_model3_tempSelect, family = 'binomial')
        
        #Use the models to create additional columns in the tempSelect DF's
        seyfried_model3_tempSelect$model_seyfried <- predict(model_seyfried, seyfried_model3_tempSelect)
        seyfried_model3_tempSelect$model_mann <- predict(model_mann, seyfried_model3_tempSelect)
        mann_model3_tempSelect$model_seyfried <- predict(model_seyfried, mann_model3_tempSelect)
        mann_model3_tempSelect$model_mann <- predict(model_mann, mann_model3_tempSelect)
  
        #Get the AUROC's and apply them to the results DF
        three_way_aruocs[number,1] <- paste(protein_1, protein_2, protein_3, sep = "_")
        three_way_aruocs[number,2] <- roc(seyfried_model3_tempSelect$DX, seyfried_model3_tempSelect$model_seyfried)$auc
        three_way_aruocs[number,3] <- roc(seyfried_model3_tempSelect$DX, seyfried_model3_tempSelect$model_mann)$auc
        three_way_aruocs[number,4] <- roc(mann_model3_tempSelect$DX, mann_model3_tempSelect$model_seyfried)$auc
        three_way_aruocs[number,5] <- roc(mann_model3_tempSelect$DX, mann_model3_tempSelect$model_mann)$auc
  
              
        #add number for next round 
        number <- number + 1
        
      }
    }
  }
}

#Calculate the average of the test on train model ones
three_way_aruocs_changes <- three_way_aruocs %>%
  mutate(averageAUROC = (seyfried_data_mann_model + mann_data_seyfried_model) / 2) %>%
  distinct(averageAUROC, .keep_all = T)

#top100 <-
three_way_aruocs_changes %>%
  top_n(100, averageAUROC) %>%
  dplyr::select(ThreeProt) %>%
  separate(ThreeProt, sep = "_", into = c("p1", "p2", "p3")) %>%
  gather(c("p1", "p2", "p3"), key = "protein", value = "Uniprot") %>%
  dplyr::select(Uniprot) %>%
  group_by(Uniprot) %>%
  count() %>%
  left_join(top21) %>%
  ggplot(aes(x = n, y = reorder(Gene, n))) +
  geom_point(size = 2) +
  theme_bw() +
  ggtitle("Count Proteins of the top100 AUROC's")

top21protgene <- top21 %>% dplyr::select(Uniprot, Gene)

forHanno <- three_way_aruocs_changes %>%
separate(ThreeProt, sep = "_", into = c("p1", "p2", "p3")) %>%
  left_join(top21protgene, by = c("p1" = "Uniprot")) %>%
    left_join(top21protgene, by = c("p2" = "Uniprot")) %>%
    left_join(top21protgene, by = c("p3" = "Uniprot"))

write.csv(forHanno, "threeCombinationAuroc.csv")

```


